{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    x_train = np.load(os.path.join(folder_path, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder_path, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder_path, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder_path, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('lr4_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лабораторной работе будет практиковаться поиск гиперпараметров. Буду рассмотрены алгоритмы поиска гиперпараметров: grid search, random search.\n",
    "\n",
    "Помимо поиска гиперпараметров будет рассмотрен алгоритм кросс-валидации, позволяющий получить более достоверную оценку качества модели в условиях недостатка данных.\n",
    "Хотя в работе предоставлена тестовая выборка, здесь она имеет сугубо теоретический характер (для получения финальной оценки) и на практике как правило недоступна. Поэтому во время подбора гиперпараметров используются лишь `x_train, y_train`. `x_test, y_test` используются лишь для получения финальной оценки, чтобы можно было видеть разницу между разными алгоритмами подбора гиперпараметров (если она будет).\n",
    "\n",
    "Выберите одну модель из списка: MLPClassifier, SGDClassifier, DecisionTreeClassifier, RandomForestClassifier, SVC.\n",
    "Для выбранной модели произведите поиск оптимальных гиперпараметров. \n",
    "\n",
    "**Требование**: поиск должен идти как минимум для двух гиперпараметров.\n",
    "\n",
    "**Требование**: в конструктор моделей передавайте `random_state=1` для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Обучение бейзлайн модели для проведения сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.7333333333333333\n",
      "Baseline Model Confusion Matrix:\n",
      "[[3 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 1 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Обучите базовую модель без изменения гиперпараметров (т.е. используются гиперпараметры по умолчанию).\n",
    "# Проанализируйте качество модели (accuracy, матрица ошибок).\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "baseline_model = SVC(random_state=1)\n",
    "baseline_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_model.predict(x_test)\n",
    "\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "conf_matrix_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy_baseline}\")\n",
    "print(f\"Baseline Model Confusion Matrix:\\n{conf_matrix_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте фунцию кросс-валидации\n",
    "\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данной функции.\n",
    "\n",
    "def kfold_cv(model_fn, eval_fn, x: np.ndarray, y: np.ndarray, n_splits=5) -> float:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_fn : callable\n",
    "        Функция-фабрика, что конструирует и возвращает новый объект модели.\n",
    "        Например: `lambda: MLPClassifier(hidden_layer_sizes=(256,))`.\n",
    "    eval_fn : callable\n",
    "        Функция вида `eval_fn(labels, predictions)`, что возвращает скаляр (значение метрики).\n",
    "    x : np.ndarray\n",
    "        Набор признаков (размерность NxD, N - количество экземпляров, D - количество признаков).\n",
    "    y : np.ndarray\n",
    "        Набор меток (размерность N)\n",
    "    n_splits : int, optional\n",
    "        Количество фолдов (подвыборок), по умолчанию 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Среднее значение метрики (что вычисляется eval_fn) по фолдам.\n",
    "    \"\"\"\n",
    "    fold_size = len(x) // n_splits\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        val_start = fold * fold_size\n",
    "        val_end = (fold + 1) * fold_size\n",
    "\n",
    "        x_val = x[val_start:val_end]\n",
    "        y_val = y[val_start:val_end]\n",
    "        x_train = np.concatenate([x[:val_start], x[val_end:]])\n",
    "        y_train = np.concatenate([y[:val_start], y[val_end:]])\n",
    "\n",
    "        model = model_fn()\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_val)\n",
    "        score = eval_fn(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score: 0.4454545454545455\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь в корректности работы функции кросс-валидации.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_fn = lambda: SVC(random_state=1)\n",
    "eval_fn = accuracy_score\n",
    "\n",
    "cv_score = kfold_cv(model_fn, eval_fn, x_train, y_train)\n",
    "print(f\"Cross-Validation Score: {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "Grid Search Time: 0.19963932037353516 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров grid search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации поиска гиперпараметров.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def grid_search(model_fn, param_grid, x_train, y_train, eval_fn, n_splits=5):\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    all_scores = []\n",
    "\n",
    "    for params in itertools.product(*param_grid.values()):\n",
    "        current_params = dict(zip(param_grid.keys(), params))\n",
    "        model = model_fn(**current_params)\n",
    "\n",
    "        score = kfold_cv(lambda: model, eval_fn, x_train, y_train, n_splits)\n",
    "        all_scores.append((current_params, score))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = current_params\n",
    "\n",
    "    return best_params, all_scores\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "best_params, all_scores = grid_search(\n",
    "    model_fn=lambda **kwargs: SVC(random_state=1, **kwargs),\n",
    "    param_grid=param_grid,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    eval_fn=accuracy_score,\n",
    "    n_splits=5\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Grid Search Time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Model Accuracy: 0.7666666666666667\n",
      "\n",
      "Grid Search Model Confusion Matrix:\n",
      "[[3 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 1 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 1 0 1 0 1]]\n",
      "\n",
      "Baseline Model Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "best_model = SVC(**best_params, random_state=1)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_grid = best_model.predict(x_test)\n",
    "\n",
    "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
    "conf_matrix_grid = confusion_matrix(y_test, y_pred_grid)\n",
    "\n",
    "print(f\"Grid Search Model Accuracy: {accuracy_grid}\\n\")\n",
    "print(f\"Grid Search Model Confusion Matrix:\\n{conf_matrix_grid}\\n\")\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy_baseline}\")\n",
    "\n",
    "#GridSearch дает значительно большую точность (0.76), чем модель с параметрами по умолчанию (0.73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "Random Search Time: 0.1957845687866211 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров random search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации поиска гиперпараметров.\n",
    "# Требование: количество итераций должно быть меньше в сравнении с grid search.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "import random\n",
    "\n",
    "def random_search(model_fn, param_dist, x_train, y_train, eval_fn, n_iter=10, n_splits=5):\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    all_scores = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        current_params = {param: random.choice(values) for param, values in param_dist.items()}\n",
    "        model = model_fn(**current_params)\n",
    "\n",
    "        score = kfold_cv(lambda: model, eval_fn, x_train, y_train, n_splits)\n",
    "        all_scores.append((current_params, score))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = current_params\n",
    "\n",
    "    return best_params, all_scores\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "best_params, all_scores = random_search(\n",
    "    model_fn=lambda **kwargs: SVC(random_state=1, **kwargs),\n",
    "    param_dist=param_dist,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    eval_fn=accuracy_score,\n",
    "    n_iter=10,\n",
    "    n_splits=5\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Random Search Time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search Model Accuracy: 0.7666666666666667\n",
      "\n",
      "Random Search Model Confusion Matrix:\n",
      "[[3 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 1 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 1 0 1 0 1]]\n",
      "\n",
      "Baseline Model Accuracy: 0.7333333333333333\n",
      "Grid Search Model Accuracy: 0.7666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test (accuracy, матрица ошибок).\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "best_model_random = SVC(**best_params_random, random_state=1)\n",
    "best_model_random.fit(x_train, y_train)\n",
    "\n",
    "y_pred_random = best_model_random.predict(x_test)\n",
    "\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "conf_matrix_random = confusion_matrix(y_test, y_pred_random)\n",
    "\n",
    "print(f\"Random Search Model Accuracy: {accuracy_random}\\n\")\n",
    "print(f\"Random Search Model Confusion Matrix:\\n{conf_matrix_random}\\n\")\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy_baseline}\")\n",
    "print(f\"Grid Search Model Accuracy: {accuracy_grid}\\n\")\n",
    "\n",
    "\n",
    "#RandomSearch дает большую точность (0.767), чем модель с параметрами по умолчанию (0.73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Доп. задание (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените байесовскую оптимизацию для поиска гиперпараметров.\n",
    "В качестве алгоритма используйте `BayesSearchCV` из пакета `scikit-optimize`.\n",
    "\n",
    "Сложность: почти бесплатный балл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Bayesian Optimization): OrderedDict({'C': 8.320950220852149, 'gamma': 'scale', 'kernel': 'rbf'})\n",
      "Bayesian Optimization Time: 9.142077445983887 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Инстанцируйте BayesSearchCV.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical\n",
    "\n",
    "bayes_param_grid = {\n",
    "    'C': Real(0.1, 10),\n",
    "    'kernel': Categorical(['linear', 'rbf']),\n",
    "    'gamma': Categorical(['scale', 'auto'])\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=SVC(random_state=1),\n",
    "    search_spaces=bayes_param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "bayes_search.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "bayes_search_time = end_time - start_time\n",
    "\n",
    "best_params_bayes = bayes_search.best_params_\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_bayes}\")\n",
    "print(f\"Bayesian Optimization Time: {bayes_search_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization Model Accuracy: 0.8\n",
      "\n",
      "Bayesian Optimization Model Confusion Matrix:\n",
      "[[3 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [1 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 1 0 0 0 0 1 0 1]]\n",
      "\n",
      "Baseline Model Accuracy: 0.7333333333333333\n",
      "Grid Search Model Accuracy: 0.7666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test (accuracy, матрица ошибок).\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "best_model_bayes = SVC(**best_params_bayes, random_state=1)\n",
    "best_model_bayes.fit(x_train, y_train)\n",
    "\n",
    "y_pred_bayes = best_model_bayes.predict(x_test)\n",
    "\n",
    "accuracy_bayes = accuracy_score(y_test, y_pred_bayes)\n",
    "conf_matrix_bayes = confusion_matrix(y_test, y_pred_bayes)\n",
    "\n",
    "print(f\"Bayesian Optimization Model Accuracy: {accuracy_bayes}\\n\")\n",
    "print(f\"Bayesian Optimization Model Confusion Matrix:\\n{conf_matrix_bayes}\\n\")\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy_baseline}\")\n",
    "print(f\"Grid Search Model Accuracy: {accuracy_grid}\\n\")\n",
    "\n",
    "\n",
    "#BayesSearchCV дает большую точность (0.8), чем модель с параметрами по умолчанию (0.73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tree of Parzen Estimators (TPE) из HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените TPE из библиотеки hyperopt для поиска гиперпараметров. Вики по HyperOpt: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "\n",
    "Сложность: чтец документаций o(*￣▽￣*)ブ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    # Принимает гиперпараметры, инстанцирует модель, обучает её, возвращает значение метрики.\n",
    "    # Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "    \n",
    "    # Напишите ваш код здесь.\n",
    "    model = SVC(\n",
    "        C=args['C'],\n",
    "        kernel=args['kernel'],\n",
    "        gamma=args['gamma'],\n",
    "        random_state=1\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_train)\n",
    "    return -accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите пространство поиска гиперпараметров\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.1, 10),\n",
    "    'kernel': hp.choice('kernel', ['linear', 'rbf']),\n",
    "    'gamma': hp.choice('gamma', ['scale', 'auto'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 101.02trial/s, best loss: -1.0]\n",
      "Best Parameters (TPE): {'C': np.float64(8.934504270945704), 'kernel': 'linear', 'gamma': 'scale'}\n",
      "TPE Search Time: 0.10500764846801758 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 2. Выведите найденные значения гиперпараметров и время работы.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "trials = Trials()\n",
    "start_time = time.time()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "end_time = time.time()\n",
    "\n",
    "tpe_search_time = end_time - start_time\n",
    "\n",
    "best_params_tpe = {\n",
    "    'C': best['C'],\n",
    "    'kernel': ['linear', 'rbf'][best['kernel']],\n",
    "    'gamma': ['scale', 'auto'][best['gamma']]\n",
    "}\n",
    "print(f\"Best Parameters (TPE): {best_params_tpe}\")\n",
    "print(f\"TPE Search Time: {tpe_search_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPE Model Accuracy: 0.7666666666666667\n",
      "\n",
      "TPE Model Confusion Matrix:\n",
      "[[3 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 1 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 1 0 1 0 1]]\n",
      "\n",
      "Baseline Model Accuracy: 0.7333333333333333\n",
      "Grid Search Model Accuracy: 0.7666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test (accuracy, матрица ошибок).\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "# Напишите ваш код здесь.\n",
    "best_model_tpe = SVC(**best_params_tpe, random_state=1)\n",
    "best_model_tpe.fit(x_train, y_train)\n",
    "\n",
    "y_pred_tpe = best_model_tpe.predict(x_test)\n",
    "\n",
    "accuracy_tpe = accuracy_score(y_test, y_pred_tpe)\n",
    "conf_matrix_tpe = confusion_matrix(y_test, y_pred_tpe)\n",
    "\n",
    "print(f\"TPE Model Accuracy: {accuracy_tpe}\\n\")\n",
    "print(f\"TPE Model Confusion Matrix:\\n{conf_matrix_tpe}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy_baseline}\")\n",
    "print(f\"Grid Search Model Accuracy: {accuracy_grid}\\n\")\n",
    "#TPE дает большую точность (0.767), чем модель с параметрами по умолчанию (0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно сделать вывод, что в большинстве случаев гиперпараметры по умолчанию уступает \n",
    "#Наилушим методом поиска гиперпараметров оказался BayesSearchCV c accuracy 0.8 для данного датасета"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "23b26f1881f590c7b459213b984520b9808dddee0bcd327e09d3f0f8eaeae1aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
