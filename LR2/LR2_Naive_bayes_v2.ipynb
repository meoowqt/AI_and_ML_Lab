{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from abc import abstractmethod\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_preds_correct(your_preds, sklearn_preds) -> bool:\n",
    "    return np.abs(your_preds - sklearn_preds).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_probs_correct(your_probs, sklearn_probs) -> bool:\n",
    "    return np.abs(your_probs - sklearn_probs).mean() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не изменяйте код этого класса!\n",
    "class NaiveBayes:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.params = dict()\n",
    "        \n",
    "    # --- PREDICTION ---\n",
    "        \n",
    "    def predict(self, x, return_probs=False):\n",
    "        \"\"\"\n",
    "        x - np.array размерности [N, dim], \n",
    "        где N - количество экземпляров данных, \n",
    "        dim -размерность одного экземпляра (количество признаков).\n",
    "        \n",
    "        Возвращает np.array размерности [N], содержащий номера классов для\n",
    "        соответствующих экземпляров.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for sample in x:\n",
    "            preds.append(\n",
    "                self.predict_single(sample, return_probs=return_probs)\n",
    "            )\n",
    "        \n",
    "        if return_probs:\n",
    "            return np.array(preds, dtype='float32')\n",
    "        \n",
    "        return np.array(preds, dtype='int32')\n",
    "    \n",
    "    # Совет: вниманительно изучите файл подсказок к данной лабораторной\n",
    "    # и сопоставьте код с описанной математикой байесовского классификатора.\n",
    "    def predict_single(self, x, return_probs=False) -> int:\n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "        \n",
    "        x - np.array размерности dim.\n",
    "        \n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "        marginal_prob = self.compute_marginal_probability(x)  # P(x) - безусловная вероятность появления x\n",
    "        \n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            prior = self.compute_prior(c)               # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            likelihood = self.compute_likelihood(x, c)  # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            \n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
    "            prob = prior * likelihood / marginal_prob\n",
    "            probs.append(prob)\n",
    "            \n",
    "        if return_probs:\n",
    "            return probs\n",
    "        \n",
    "        return np.argmax(probs)\n",
    "    \n",
    "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
    "    @abstractmethod\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(c) - априорная вероятность появления класса c.\n",
    "    @abstractmethod\n",
    "    def compute_prior(self, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(x|c) - вероятность наблюдения экземпляра x в предположении, что он принаждлежит c.\n",
    "    @abstractmethod\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._estimate_prior(y)\n",
    "        self._estimate_params(x, y)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_params(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Наивный классификатор Байеса: гауссово распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель. \n",
    "\n",
    "Пункты оценки:\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(C_k|x) = P(x|theta) * P(C_k) / P(x)\n",
    "\n",
    "class NaiveGauss(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        marginal_prob = 0.0\n",
    "        for c in range(self.n_classes):\n",
    "            prior = self.compute_prior(c)\n",
    "            likelihood = self.compute_likelihood(x, c)\n",
    "            marginal_prob += prior * likelihood\n",
    "        return marginal_prob\n",
    "    \n",
    "    def compute_prior(self, c) -> float:\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        return self.params['prior'][c]\n",
    "    \n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        mean = self.params['mean'][c]\n",
    "        std = self.params['std'][c]\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "        return np.prod((1 / (np.sqrt(2 * np.pi * std ** 2))) * exponent)\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def _estimate_prior(self, y):\n",
    "        class_counts = np.bincount(y)\n",
    "        total_samples = len(y)\n",
    "        self.params['prior'] = class_counts / total_samples\n",
    "        \n",
    "    \n",
    "    def _estimate_params(self, x, y):\n",
    "        self.params['mean'] = []\n",
    "        self.params['std'] = []\n",
    "        for c in range(self.n_classes):\n",
    "            x_c = x[y == c]\n",
    "            class_mean = np.mean(x_c, axis=0)\n",
    "            self.params['mean'].append(class_mean)\n",
    "            class_std = np.std(x_c, axis=0)\n",
    "            self.params['std'].append(class_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "model = NaiveGauss(n_classes=len(np.unique(y_train)))\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "probs = model.predict(x_test, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy моего наивного Байеса: 1.0\n",
      "F1 моего наивного Байеса: 1.0\n",
      "Recall моего наивного Байеса: 1.0\n",
      "Precision моего наивного Байеса: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "my_accuracy = accuracy_score(y_test, preds)\n",
    "my_f1_score = f1_score(y_test, preds, average='weighted')\n",
    "my_recall_score = recall_score(y_test, preds, average='weighted')\n",
    "my_precision_score = precision_score(y_test, preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy моего наивного Байеса: {my_accuracy}\")\n",
    "print(f\"F1 моего наивного Байеса: {my_f1_score}\")\n",
    "print(f\"Recall моего наивного Байеса: {my_recall_score}\")\n",
    "print(f\"Precision моего наивного Байеса: {my_precision_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели из sklearn наивного Байеса: 1.0\n",
      "F1 модели из sklearn наивного Байеса: 1.0\n",
      "Recall модели из sklearn наивного Байеса: 1.0\n",
      "Precision модели из sklearn наивного Байеса: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "sklearn_model = GaussianNB()\n",
    "sklearn_model.fit(x_train, y_train)\n",
    "sklearn_preds = sklearn_model.predict(x_test)\n",
    "sklearn_probs = sklearn_model.predict_proba(x_test)\n",
    "\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_preds)\n",
    "sklearn_f1_score = f1_score(y_test, sklearn_preds, average='weighted')\n",
    "sklearn_recall_score = recall_score(y_test, sklearn_preds, average='weighted')\n",
    "sklearn_precision_score = precision_score(y_test, sklearn_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy модели из sklearn наивного Байеса: {sklearn_accuracy}\")\n",
    "print(f\"F1 модели из sklearn наивного Байеса: {sklearn_f1_score}\")\n",
    "print(f\"Recall модели из sklearn наивного Байеса: {sklearn_recall_score}\")\n",
    "print(f\"Precision модели из sklearn наивного Байеса: {sklearn_precision_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанные классы совпадают с моделью sklearn\n",
      "Предсказанные вероятности совпадают с моделью sklearn\n"
     ]
    }
   ],
   "source": [
    "#тут добавила оценку из пунктов оценки :)\n",
    "\n",
    "if assert_preds_correct(preds, sklearn_preds):\n",
    "    print(\"Предсказанные классы совпадают с моделью sklearn\")\n",
    "else:\n",
    "    print(\"Предсказанные классы НЕ совпадают с моделью sklearn\")\n",
    "\n",
    "if assert_probs_correct(probs, sklearn_probs):\n",
    "    print(\"Предсказанные вероятности совпадают с моделью sklearn\")\n",
    "else:\n",
    "    print(\"Предсказанные вероятности НЕ совпадают с моделью sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Итоги:\n",
    "## 1. Совпали метрики, значит и моя модель, и модель из sklearn\n",
    "## 2. Совпали предсказанные классы у моей модели и у модели sklearn\n",
    "## 3. Совпали значения предсказанных вероятностей принадлежности классами у моей модели и у модели sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Упрощение наивного классификатора Байеса для гауссова распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберите из класса NaiveBayes 'лишние' вычисления и удалите код, что соответствует этим вычислениям. Под 'лишним' подразумеваются вещи, что не влияют на итоговое решение о принадлежности классу (значения вероятностей при этом могу стать некорректными, но в данном задании это допустимо).\n",
    "\n",
    "Напишите в клетке ниже код упрощенного 'классификатора Гаусса' и убедитесь, что его ответы (не значения вероятностей) совпадают с ответами классификатора из задания 1. Для сравнения ответов используйте функцию `assert_preds_correct`.\n",
    "\n",
    "Указание: работайте в предположении, что классы равновероятны.\n",
    "\n",
    "Подсказка: упростить необходимо метод `predict_single`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedNaiveGauss(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        return 1.0\n",
    "    \n",
    "    def compute_prior(self, c) -> float:\n",
    "        return 1.0 / self.n_classes\n",
    "    \n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        mean = self.params['mean'][c]\n",
    "        std = self.params['std'][c]\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "        return np.prod((1 / (np.sqrt(2 * np.pi * std ** 2))) * exponent)\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "    \n",
    "    def _estimate_params(self, x, y):\n",
    "        self.params['mean'] = []\n",
    "        self.params['std'] = []\n",
    "        for c in range(self.n_classes):\n",
    "            x_c = x[y == c]\n",
    "            class_mean = np.mean(x_c, axis=0)\n",
    "            self.params['mean'].append(class_mean)\n",
    "            class_std = np.std(x_c, axis=0)\n",
    "            self.params['std'].append(class_std)\n",
    "    \n",
    "    def predict_single(self, x, return_probs=False) -> int:\n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "        \n",
    "        x - np.array размерности dim.\n",
    "        \n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "        \n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            prior = self.compute_prior(c)               # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            likelihood = self.compute_likelihood(x, c)  # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            \n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c)\n",
    "            prob = prior * likelihood\n",
    "            probs.append(prob)\n",
    "            \n",
    "        if return_probs:\n",
    "            return probs\n",
    "        \n",
    "        return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "simplified_model = SimplifiedNaiveGauss(n_classes=len(np.unique(y_train)))\n",
    "simplified_model.fit(x_train, y_train)\n",
    "\n",
    "simplified_preds = simplified_model.predict(x_test)\n",
    "simplified_probs = simplified_model.predict(x_test, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy упрощенной модели наивного Байеса: 1.0\n",
      "F1 упрощенной модели наивного Байеса: 1.0\n",
      "Recall упрощенной модели наивного Байеса: 1.0\n",
      "Precision упрощенной модели наивного Байеса: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "simplified_accuracy = accuracy_score(y_test, simplified_preds)\n",
    "simplified_f1_score = f1_score(y_test, simplified_preds, average='weighted')\n",
    "simplified_recall_score = recall_score(y_test, simplified_preds, average='weighted')\n",
    "simplified_precision_score = precision_score(y_test, simplified_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy упрощенной модели наивного Байеса: {simplified_accuracy}\")\n",
    "print(f\"F1 упрощенной модели наивного Байеса: {simplified_f1_score}\")\n",
    "print(f\"Recall упрощенной модели наивного Байеса: {simplified_recall_score}\")\n",
    "print(f\"Precision упрощенной модели наивного Байеса: {simplified_precision_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанные классы совпадают с упрощенной модели\n",
      "Предсказанные вероятности НЕ совпадают с упрощенной модели\n"
     ]
    }
   ],
   "source": [
    "if assert_preds_correct(preds, simplified_preds):\n",
    "    print(\"Предсказанные классы совпадают с упрощенной модели\")\n",
    "else:\n",
    "    print(\"Предсказанные классы НЕ совпадают с упрощенной модели\")\n",
    "\n",
    "if assert_probs_correct(probs, simplified_probs):\n",
    "    print(\"Предсказанные вероятности совпадают с упрощенной модели\")\n",
    "else:\n",
    "    print(\"Предсказанные вероятности НЕ совпадают с упрощенной модели\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объясните в комментариях к этой клетке суть проделанных изменений: почему удаленный код является лишним?\n",
    "\n",
    "#Метод compute_marginal_probability теперь возвращает константу 1.0, так как безусловная вероятность P(x) не влияет на выбор класса\n",
    "#Если все классы равновероятны, то априорная вероятность для каждого класса равна 1.0 / self.n_classes\n",
    "#Метод _estimate_prior больше не нужен, т.к. мы предполагаем равновероятность классов\n",
    "#В методе predict_single убрала деление на безусловную вероятность P(x), т.к. она не влияет на выбор класса с максимальной вероятностью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Наивный классификатор Байеса: мультиномиальное распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель.\n",
    "\n",
    "Подсказка: в определении функции правдоподобия много факториалов. Для избежания численного переполнения посчитайте сначала логарифм функции правдоподобия (на бумаге), после примените экспоненту для получения значения вероятности.\n",
    "\n",
    "Пункты оценки:\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True.\n",
    "\n",
    "Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveMultinomial(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        \"\"\"Вычисляет безусловную вероятность P(x) как сумму по всем классам.\"\"\"\n",
    "        marginal_prob = 0.0\n",
    "        for c in range(self.n_classes):\n",
    "            prior = self.compute_prior(c)\n",
    "            likelihood = self.compute_likelihood(x, c)\n",
    "            marginal_prob += prior * likelihood\n",
    "        return marginal_prob\n",
    "\n",
    "    def compute_prior(self, c) -> float:\n",
    "        \"\"\"Возвращает априорную вероятность класса c.\"\"\"\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Сумма априорных вероятностей должна быть равна 1, но равна {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Индекс класса должен быть < {self.n_classes}, но получен {c}.'\n",
    "        return self.params['prior'][c]\n",
    "\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        \"\"\"Вычисляет правдоподобие P(x|c) для заданного класса c и вектора признаков x.\"\"\"\n",
    "        assert c < self.n_classes, f'Индекс класса должен быть < {self.n_classes}, но получен {c}.'\n",
    "        total_sum = sum(x)\n",
    "        log_likelihood = np.sum(np.log(np.arange(total_sum, 0, -1))) - sum(np.log(xi) for xi in x if xi > 0)\n",
    "        for feature_idx, feature_value in enumerate(x):\n",
    "            if feature_value > 0:\n",
    "                log_likelihood += feature_value * log(self.params['likelihood'][c][feature_idx])\n",
    "        return exp(log_likelihood)\n",
    "\n",
    "    def _estimate_prior(self, y):\n",
    "        \"\"\"Оценивает априорные вероятности P(c) на основе обучающей выборки.\"\"\"\n",
    "        self.params['prior'] = np.bincount(y) / len(y)\n",
    "\n",
    "    def _estimate_params(self, x, y):\n",
    "        \"\"\"Оценивает параметры правдоподобия P(x|c) с использованием сглаживания Лапласа.\"\"\"\n",
    "        self.params['likelihood'] = []\n",
    "        for c in range(self.n_classes):\n",
    "            x_c = x[y == c]\n",
    "            feature_sums = np.sum(x_c, axis=0)\n",
    "            total_sum = np.sum(feature_sums)\n",
    "            likelihood = (feature_sums + 1) / (total_sum + x.shape[1])\n",
    "            self.params['likelihood'].append(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "nm_model = NaiveMultinomial(n_classes=len(np.unique(y_test)))\n",
    "nm_model.fit(x_train, y_train)\n",
    "\n",
    "nm_preds= nm_model.predict(x_test)\n",
    "nm_probs= nm_model.predict(x_test, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели с мультиномиальным распределение наивного Байеса: 0.8173076923076923\n",
      "F1 модели с мультиnm_predsномиальным распределени наивного Байеса: 0.8172889197856059\n",
      "Recall модели с мультиномиальным распределени наивного Байеса: 0.8173076923076923\n",
      "Precision модели с мультиномиальным распределени наивного Байеса: 0.8173373404436152\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "nm_accuracy = accuracy_score(y_test, nm_preds)\n",
    "nm_f1_score = f1_score(y_test, nm_preds, average='weighted')\n",
    "nm_recall_score = recall_score(y_test, nm_preds, average='weighted')\n",
    "nm_precision_score = precision_score(y_test, nm_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy модели с мультиномиальным распределение наивного Байеса: {nm_accuracy}\")\n",
    "print(f\"F1 модели с мультиnm_predsномиальным распределени наивного Байеса: {nm_f1_score}\")\n",
    "print(f\"Recall модели с мультиномиальным распределени наивного Байеса: {nm_recall_score}\")\n",
    "print(f\"Precision модели с мультиномиальным распределени наивного Байеса: {nm_precision_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели из sklearn наивного Байеса: 0.8173076923076923\n",
      "F1 модели из sklearn наивного Байеса: 0.8172889197856059\n",
      "Recall модели из sklearn наивного Байеса: 0.8173076923076923\n",
      "Precision модели из sklearn наивного Байеса: 0.8173373404436152\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (MultinomialNB)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "sklearn_model = MultinomialNB()\n",
    "sklearn_model.fit(x_train, y_train)\n",
    "\n",
    "sklearn_preds = sklearn_model.predict(x_test)\n",
    "sklearn_probs = sklearn_model.predict_proba(x_test)\n",
    "\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_preds)\n",
    "sklearn_f1_score = f1_score(y_test, sklearn_preds, average='weighted')\n",
    "sklearn_recall_score = recall_score(y_test, sklearn_preds, average='weighted')\n",
    "sklearn_precision_score = precision_score(y_test, sklearn_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy модели из sklearn наивного Байеса: {sklearn_accuracy}\")\n",
    "print(f\"F1 модели из sklearn наивного Байеса: {sklearn_f1_score}\")\n",
    "print(f\"Recall модели из sklearn наивного Байеса: {sklearn_recall_score}\")\n",
    "print(f\"Precision модели из sklearn наивного Байеса: {sklearn_precision_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанные классы совпадают с моделью из sklearn\n",
      "Предсказанные вероятности совпадают с моделью из sklearn\n"
     ]
    }
   ],
   "source": [
    "if assert_preds_correct(nm_preds, sklearn_preds):\n",
    "    print(\"Предсказанные классы совпадают с моделью из sklearn\")\n",
    "else:\n",
    "    print(\"Предсказанные классы НЕ совпадают с моделью из sklearn\")\n",
    "\n",
    "if assert_probs_correct(nm_probs, sklearn_probs):\n",
    "    print(\"Предсказанные вероятности совпадают с моделью из sklearn\")\n",
    "else:\n",
    "    print(\"Предсказанные вероятности НЕ совпадают с моделью из sklearn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
