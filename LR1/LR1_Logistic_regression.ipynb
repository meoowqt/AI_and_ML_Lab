{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        rng = np.random.default_rng(seed=0)\n",
    "        self.w = rng.normal(size=(dim, 1)) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        \n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        assert len(x) == len(y), \\\n",
    "            \"Количество экземпляров в массиве X не равно количеству меток в массиве Y. \" + \\\n",
    "            f\"Полученные размеры: len(X) = {len(x)}, len(Y) = {len(y)}.\"\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x29537815e20>"
      ]
     },
     "execution_count": 1467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "\n",
    "model = LogisticRegression(dim=784)\n",
    "\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.904545\n"
     ]
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели, \n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy_reg = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_reg: .6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`. \n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self):\n",
    "        print('Hello, brother!')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        return np.zeros(x.shape[0], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, brother!\n",
      "Accuracy: 0.909091\n"
     ]
    }
   ],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "\n",
    "dummy_classifier = DummyClassifier()\n",
    "predictions = dummy_classifier.predict(x_test)\n",
    "\n",
    "accuracy_dum = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy_dum:.6f}\")\n",
    "\n",
    "# accuracy дает не точную картину, так как присутствует дисбаланс классов \n",
    "# в данном случае 0 намного больше, чем 1\n",
    "# отсюда и возникает большой процент в accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.000000\n",
      "Recall: 0.000000\n",
      "Precision: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Используйте дополнительные метрики (f1-score, recall, precision) из пакета sklearn для анализа \"глупого классификатора\".\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "    \n",
    "recall = recall_score(y_test, predictions)\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "    \n",
    "precision = precision_score(y_test, predictions, zero_division=0) # добавила параметр, что не было деления на 0\n",
    "print(f\"Precision: {precision:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.400000\n",
      "Recall: 0.350000\n",
      "Precision: 0.466667\n"
     ]
    }
   ],
   "source": [
    "# Используя те же метрики, проанализируйте обученную вами модель логистической регрессии.\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "    \n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "    \n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объясните результат, описав его комментариями в этой клетке.\n",
    "\n",
    "# видно, что у \"глупого классификатора\" метрики равны 0, что говорит о том, \n",
    "# что он ни разу не смог предсказать 1 (т.к. он предсказывает только 0)\n",
    "\n",
    "# для моей модели результаты оказались лучше\n",
    "# если предсказана 1, то мы уверены в результате на 47%\n",
    "# из всех предсказаний 1 лишь 35% будет найдено классификатором\n",
    "# гармоническое среднее будет 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 200\n",
      "Class 1: 20\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "y_test = y_test.astype(int)\n",
    "        \n",
    "class_counts = np.bincount(y_test)\n",
    "for class_label, count in enumerate(class_counts):\n",
    "    print(f\"Class {class_label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предложите способ улучшения качества модели. Подсказка: добавление дубликатов в данные.\n",
    "# Указание: не изменяйте тестовую выборку.\n",
    "\n",
    "class_zero = np.where(y_train == 0)[0]\n",
    "class_one = np.where(y_train == 1)[0]\n",
    "\n",
    "num_duplicates = (len(class_zero) - len(class_one))*2\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    duplicate = np.random.choice(class_one, size=num_duplicates, replace=True)\n",
    "    x_train_with_duplicate = np.vstack((x_train, x_train[duplicate]))\n",
    "    y_train_with_duplicate = np.hstack((y_train, y_train[duplicate]))\n",
    "else:\n",
    "    x_train_with_duplicate = x_train\n",
    "    y_train_with_duplicate = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x2953780e8d0>"
      ]
     },
     "execution_count": 1476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "model_log = LogisticRegression(dim=784)\n",
    "model_log.fit(x_train_with_duplicate, y_train_with_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954545\n",
      "F1-score: 0.761905\n",
      "Recall: 0.800000\n",
      "Precision: 0.727273\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь сбалансировать данные таким образом, чтобы новая модель была ощутимо лучше старой.\n",
    "\n",
    "predictions_new = model_log.predict(x_test)\n",
    "\n",
    "accuracy_new = accuracy_score(y_test, predictions_new)\n",
    "print(f\"Accuracy: {accuracy_new:.6f}\")\n",
    "        \n",
    "f1_new = f1_score(y_test, predictions_new)\n",
    "print(f\"F1-score: {f1_new:.6f}\")\n",
    "        \n",
    "recall_new = recall_score(y_test, predictions_new)\n",
    "print(f\"Recall: {recall_new:.6f}\")\n",
    "        \n",
    "precision_new = precision_score(y_test, predictions_new, zero_division=0)\n",
    "print(f\"Precision: {precision_new:.6f}\")\n",
    "\n",
    "# ура!!! модель примерно в полтора-два раза стала лучше "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x29537817bf0>"
      ]
     },
     "execution_count": 1479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель но этом наборе данных.\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.570000\n",
      "F1-score: 0.619469\n",
      "Recall: 0.777778\n",
      "Precision: 0.514706\n"
     ]
    }
   ],
   "source": [
    "# Проанализируйте качество модели.\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy_reg = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_reg: .6f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "    \n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "    \n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "\n",
    "#accuracy и precision небольшие, предсказывает не очень :((, зато recall неплохое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, ...).\n",
    "# Объедините трансформированные данные с исходными (важно: количество экземпляров в x_train не должно увеличиться).\n",
    "\n",
    "bigX_train = np.concatenate((x_train, np.sin(x_train), np.cos(x_train)), axis=1)\n",
    "bigX_test = np.concatenate((x_test, np.sin(x_test), np.cos(x_test)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x2953780cd70>"
      ]
     },
     "execution_count": 1482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "\n",
    "model = LogisticRegression(dim=6)\n",
    "\n",
    "model.fit(bigX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.000000\n",
      "F1-score: 1.000000\n",
      "Recall: 1.000000\n",
      "Precision: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь добиться точности в 100%!\n",
    "\n",
    "y_pred = model.predict(bigX_test)\n",
    "\n",
    "accuracy_reg = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_reg: .6f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "    \n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "    \n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 'Упрощение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность: легко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Модифицируйте класс логистической регрессии так, чтобы в нём не использовалась сигмоида.\n",
    "То есть вывод о предсказанном классе должен делаться на основе значений \"до сигмоиды\".\n",
    "Вспомогательная ссылка: https://en.wikipedia.org/wiki/Logit\n",
    "\"\"\"\n",
    "\n",
    "class MLogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        np.random.seed(43)\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        \n",
    "        return np.array(x > 0).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перенесите обученные веса модели из пункта 1.3 в новую модель с модифицированным кодом\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')\n",
    "model_neww = MLogisticRegression()\n",
    "\n",
    "model_neww.w = model_log.w.copy()\n",
    "model_neww.b = model_log.b.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954545\n",
      "F1-score: 0.761905\n",
      "Recall: 0.800000\n",
      "Precision: 0.727273\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь, что предсказания модели с модифицированными кодом совпадают с предсказаниями\n",
    "# модели из пункта 1.3\n",
    "predictions_new = model_neww.predict(x_test)\n",
    "\n",
    "accuracy_new = accuracy_score(y_test, predictions_new)\n",
    "print(f\"Accuracy: {accuracy_new:.6f}\")\n",
    "        \n",
    "f1_new = f1_score(y_test, predictions_new)\n",
    "print(f\"F1-score: {f1_new:.6f}\")\n",
    "        \n",
    "recall_new = recall_score(y_test, predictions_new)\n",
    "print(f\"Recall: {recall_new:.6f}\")\n",
    "        \n",
    "precision_new = precision_score(y_test, predictions_new, zero_division=0)\n",
    "print(f\"Precision: {precision_new:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, n_classes, dim=2):\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.dim = dim\n",
    "        self.models = [LogisticRegression(dim) for _ in range(n_classes)]\n",
    "    \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            y_binary = (y == i).astype(int)\n",
    "            self.models[i].fit(x, y_binary, iters=iters, lr=lr)\n",
    "    \n",
    "    def predict(self, x):\n",
    "         # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        probabilities = np.zeros((x.shape[0], self.n_classes))\n",
    "        for i in range(self.n_classes):\n",
    "            probabilities[:, i] = self.models[i].predict(x, probs=True).flatten()\n",
    "        \n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс 0: 48\n",
      "Класс 1: 39\n",
      "Класс 2: 52\n",
      "Класс 3: 49\n",
      "Класс 4: 39\n",
      "Класс 5: 50\n",
      "Класс 6: 42\n",
      "Класс 7: 43\n",
      "Класс 8: 37\n",
      "Класс 9: 51\n",
      "Количество классов: 10\n"
     ]
    }
   ],
   "source": [
    "#Cмотрим сколько классов\n",
    "y_test = y_test.astype(int)\n",
    "        \n",
    "class_counts = np.bincount(y_test)\n",
    "for class_label, count in enumerate(class_counts):\n",
    "    print(f\"Класс {class_label}: {count}\")\n",
    "\n",
    "print(f\"Количество классов: {len(np.unique(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n",
    "model = MulticlassLogisticRegression(n_classes=10, dim=64)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935556\n",
      "F1-score: 0.932422\n",
      "Recall: 0.935556\n",
      "Precision: 0.937119\n"
     ]
    }
   ],
   "source": [
    "predictions= model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.6f}\")\n",
    "\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "print(f\"F1-score: {f1:.6f}\")\n",
    "        \n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "        \n",
    "precision = precision_score(y_test, predictions, zero_division=0, average='weighted')\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "\n",
    "#Точность вроде бы неплохая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Softmax классификатор.</b> Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс классификатора, основанного на функции Softmax.\n",
    "Алгоритм работы данного классификатора:\n",
    "x - вектор (экземпляр данных) размерности dim.\n",
    "W - матрица весов размерности [dim, n_classes].\n",
    "\n",
    "Ответ классификатора формируется как:\n",
    "logits = x * W - матричное умножение\n",
    "p = softmax(logits)\n",
    "class_id = argmax(p)\n",
    "\n",
    "Для данного классификатора требуется модифицировать алгоритм обучения в методе fit.\n",
    "\n",
    "Вспомогательные ресурсы:\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\"\"\"\n",
    "\n",
    "class SoftmaxClassificator:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор на наборе данных из задания 1 (опционально). \n",
    "# Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
